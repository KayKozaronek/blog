{
  
    
        "post0": {
            "title": "Weekly Goal Tracking Template",
            "content": "Weekly Goal Tracking Template . This is a template to keep track of my weekly goals. . Status: . Here’s the progress of last weeks goals. . What Comment Done Points .   |   | :white_check_mark: |   | .   |   | :white_check_mark: |   | .   |   | :white_check_mark: |   | .   |   | :white_check_mark: |   | .   |   | :white_check_mark: |   | .   |   | :white_check_mark: |   | .   |   | :white_check_mark: |   | .   |   | :white_check_mark: |   | .   |   | :construction: |   | .   |   | :x: |   | . Total Points |   |   |   | . Goals: . This week I want to focus on XYZ … | It seems like this is particularly valuable because … | I hope to achieve … | This could enable me to do … | How and to whom am I useful this week? | . What Comment Done Points .   |   | :white_check_mark: |   | .   |   | :heavy_check_mark: |   | .   |   | :white_check_mark: |   | .   |   | :white_check_mark: |   | .   |   | :white_check_mark: |   | .   |   | :white_check_mark: |   | .   |   | :white_check_mark: |   | .   |   | :white_check_mark: |   | .   |   | :construction: |   | .   |   | :x: |   | . Total Points |   |   |   | . Explore in upcoming week(s): . Item 1 | Item 2 | .",
            "url": "https://kaykozaronek.github.io/blog/markdown/2022/06/29/Weekly-Goals-Template.html",
            "relUrl": "/markdown/2022/06/29/Weekly-Goals-Template.html",
            "date": " • Jun 29, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Exploring the OpenAI critiques dataset",
            "content": "Installs . !pip install datasets !pip install transformers . Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/ Collecting datasets Downloading datasets-2.3.2-py3-none-any.whl (362 kB) |████████████████████████████████| 362 kB 7.4 MB/s Requirement already satisfied: tqdm&gt;=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0) Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5) Collecting responses&lt;0.19 Downloading responses-0.18.0-py3-none-any.whl (38 kB) Collecting huggingface-hub&lt;1.0.0,&gt;=0.1.0 Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB) |████████████████████████████████| 101 kB 13.3 MB/s Collecting xxhash Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB) |████████████████████████████████| 212 kB 58.8 MB/s Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13) Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4) Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6) Requirement already satisfied: dill&lt;0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1) Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3) Requirement already satisfied: requests&gt;=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0) Requirement already satisfied: pyarrow&gt;=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1) Collecting fsspec[http]&gt;=2021.05.0 Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB) |████████████████████████████████| 140 kB 57.8 MB/s Collecting aiohttp Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB) |████████████████████████████████| 1.1 MB 50.5 MB/s Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub&lt;1.0.0,&gt;=0.1.0-&gt;datasets) (3.7.1) Collecting pyyaml&gt;=5.1 Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB) |████████████████████████████████| 596 kB 70.2 MB/s Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub&lt;1.0.0,&gt;=0.1.0-&gt;datasets) (4.1.1) Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;datasets) (3.0.9) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.19.0-&gt;datasets) (1.24.3) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.19.0-&gt;datasets) (2.10) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.19.0-&gt;datasets) (3.0.4) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.19.0-&gt;datasets) (2022.6.15) Collecting urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB) |████████████████████████████████| 127 kB 66.7 MB/s Collecting asynctest==0.13.0 Downloading asynctest-0.13.0-py3-none-any.whl (26 kB) Collecting yarl&lt;2.0,&gt;=1.0 Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB) |████████████████████████████████| 271 kB 46.5 MB/s Collecting async-timeout&lt;5.0,&gt;=4.0.0a3 Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB) Collecting multidict&lt;7.0,&gt;=4.5 Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB) |████████████████████████████████| 94 kB 3.7 MB/s Collecting frozenlist&gt;=1.1.1 Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB) |████████████████████████████████| 144 kB 80.3 MB/s Collecting aiosignal&gt;=1.1.2 Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB) Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;datasets) (21.4.0) Requirement already satisfied: charset-normalizer&lt;3.0,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;datasets) (2.0.12) Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&gt;datasets) (3.8.0) Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;datasets) (2.8.2) Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;datasets) (2022.1) Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;datasets) (1.15.0) Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, responses, huggingface-hub, datasets Attempting uninstall: urllib3 Found existing installation: urllib3 1.24.3 Uninstalling urllib3-1.24.3: Successfully uninstalled urllib3-1.24.3 Attempting uninstall: pyyaml Found existing installation: PyYAML 3.13 Uninstalling PyYAML-3.13: Successfully uninstalled PyYAML-3.13 ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible. Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.3.2 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.8.1 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2 Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/ Collecting transformers Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB) |████████████████████████████████| 4.4 MB 8.3 MB/s Requirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1) Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0) Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4) Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0) Requirement already satisfied: tqdm&gt;=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0) Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1) Collecting tokenizers!=0.11.3,&lt;0.13,&gt;=0.11.1 Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB) |████████████████████████████████| 6.6 MB 54.0 MB/s Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3) Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2) Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub&lt;1.0,&gt;=0.1.0-&gt;transformers) (4.1.1) Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging&gt;=20.0-&gt;transformers) (3.0.9) Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&gt;transformers) (3.8.0) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (1.25.11) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (2.10) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (2022.6.15) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (3.0.4) Installing collected packages: tokenizers, transformers Successfully installed tokenizers-0.12.1 transformers-4.20.1 . Imports . from datasets import load_dataset from datetime import datetime, timedelta import pandas as pd import matplotlib.pyplot as plt import torch import torch.nn.functional as F . The Data . 1. Base Dataset . The Base Dataset it structured like so: . Train . id | split | time | labeler | is_topic_based_summarization | data passage text | title | . | questions list of multiple question-answer pairs (dictionaries) | . | . | . | Test . etc. | . | . base_url = &quot;https://openaipublic.blob.core.windows.net/critiques/dataset/base/&quot; base_dataset = load_dataset(&#39;json&#39;, data_files={&#39;train&#39;: base_url + &#39;train.jsonl.gz&#39;, &#39;test&#39;: base_url + &#39;test.jsonl.gz&#39;}) base_dataset . Using custom data configuration default-b6bdeb08a451c657 Reusing dataset json (/root/.cache/huggingface/datasets/json/default-b6bdeb08a451c657/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5) . DatasetDict({ train: Dataset({ features: [&#39;id&#39;, &#39;split&#39;, &#39;time&#39;, &#39;labeler&#39;, &#39;is_topic_based_summarization&#39;, &#39;data&#39;], num_rows: 11232 }) test: Dataset({ features: [&#39;id&#39;, &#39;split&#39;, &#39;time&#39;, &#39;labeler&#39;, &#39;is_topic_based_summarization&#39;, &#39;data&#39;], num_rows: 3857 }) }) . Figuring out the structure of the dataset . df = pd.DataFrame(base_dataset[&#39;train&#39;]) df.head() . id split time labeler is_topic_based_summarization data . 0 Hvwa1M6h1l81jmLcI2WdliTDayc6ik | train | 1.654295e+09 | 9d66ba714984b4ac37359c8a26b065d2d5e1d508b349a2... | True | {&#39;passage&#39;: {&#39;text&#39;: &#39;[Between now and the end... | . 1 tCYeeDnFlAqrHk9HHYV5BnC4JD5eYQ | train | 1.654295e+09 | d95e9d66406f3756657b3e159c883527a54ebe2d11fcb6... | False | {&#39;passage&#39;: {&#39;text&#39;: &#39; The hikers had left a m... | . 2 YfuuobgOYOdMtT7nSuaLFaJ7yRBjX6 | train | 1.654295e+09 | 8774b0664d5c0ab1502c35813c97e6ae44b477c0ac0a7c... | False | {&#39;passage&#39;: {&#39;text&#39;: &#39;CHARLESTON EXECUTIVE AIR... | . 3 b5KtNkpspmPl9Is6uAaDTBAGKFsUZg | train | 1.654295e+09 | c386a07c8ceed1b1dfcd2126015c772310f9ccf5c34a82... | False | {&#39;passage&#39;: {&#39;text&#39;: &#39;I reach into my pocket t... | . 4 08dDPy00rGm3wNIZPusqxSL8A8ADxu | train | 1.654295e+09 | 9217c5bbd255314f3a9222a5c253cc60571b546da6c393... | False | {&#39;passage&#39;: {&#39;text&#39;: &#39;Whatever had wiped out a... | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; df[&#39;data&#39;][0].keys() . dict_keys([&#39;passage&#39;, &#39;questions&#39;]) . df[&#39;data&#39;][0][&#39;passage&#39;].keys() . dict_keys([&#39;text&#39;, &#39;title&#39;]) . df[&#39;data&#39;][0][&#39;passage&#39;][&#39;text&#39;] . &#34;[Between now and the end of the year, Justin Trudeau&#39;s capacity to forge a consensus in Parliament, on the federal-provincial front and, possibly, within his own caucus will be tested as the rubber meets the road on some key campaign commitments, writes Chantal Hébert.] n n[Chantal Hébert] n nChantal HébertNational Affairs Columnist n n__Sat., Nov. 19, 20163 min. read n nArticle was updated Nov. 18, 2016 n nIf you have been enjoying Canada’s comparatively cool political climate since Justin Trudeau became prime minister, make the most of what may be the last days of the season. n nBy all indications, the political temperature is about to rise as deadlines looms on three potentially troublesome fronts for the Liberal government. n nBetween now and the end of the year, the prime minister’s capacity to forge a consensus in Parliament, on the federal-provincial front and, possibly, within his own caucus will be tested as the rubber meets the road on some key campaign commitments. n nOn or before Dec. 1, the special committee that has been exploring a reform of Canada’s voting system will report its findings to the government. If the Liberals have a principled position on this issue, they have been doing a great job of keeping it under wraps. n nThe committee report should signal the beginning of the end of the Liberal game of hide-and-seek. n nThe opposition parties hold the majority at the electoral reform table and, in any event, no government is bound to implement the prescription of a committee. If such an obligation existed, Canada’s new law on medically assisted suicide would be a lot less restrictive. But if Trudeau is presented with an opposition consensus as to the way forward on the voting system he will, at a minimum, have to come up with the kind of coherent response that has been sorely lacking to date. n nThis week, democratic reform minister Maryam Monsef reported, on the basis of her own consultations, that there was no consensus within the public as to a preferred voting system. The representations made to the committee on the other hand have tended to favour a more proportional system. Consensus, in this instance, is very much in the opportunistic eye of the beholder. But more on that later in this column. n nThe odds of a majority committee report increased this week when the NDP signalled that it could support the Conservative call for any new voting system to be put to a national referendum. If there is solid majority within the electorate to be found for anything pertaining to electoral reform, it revolves around the notion that a change should be approved through a national plebiscite. n nOne way or another, it does seem that at least one part of Trudeau’s promise will not be fulfilled. In the still unlikely scenario that the Liberals sign off on a national plebiscite, the debate would shift to the rewriting of the federal referendum law and then to the actual holding of a national vote. Getting all that done within the time frame Elections Canada says it needs to put a different voting system in place for 2019 would be extremely difficult. And that is, of course, assuming a reform proposal wins the day. n nOn Dec. 9, Trudeau is tentatively scheduled to meet with the premiers to put the finishing touches on the country’s climate change strategy. The first ministers have not gathered since the prime minister signalled his intention to set a floor price on carbon. In the interval, Donald Trump’s victory and the expectation that his administration will not follow up on the Paris climate accord have added grist to the mill of opponents of a Canadian carbon tax. n nTrudeau does not lack for provincial allies on carbon pricing but the same is not true of his plan to cut the annual increase of the health transfer to 3 per cent. The prime minister wants to avoid a linkage between the two files. Absent some conciliatory federal move on health-care funding, that linkage may be hard to avoid next month and not just on carbon pricing. n nDec. 19 is the deadline for the federal cabinet to decide the fate of Kinder Morgan’s plan to increase the capacity of the TransMountain pipeline. It links Alberta to the coast off Vancouver. In the wake of the American election, Energy Minister Jim Carr has argued that Trump’s victory and the prospect of a revival of the Keystone XL project did not diminish the need for more pipeline capacity in Canada. n nTrudeau has long said he would not proceed with a pipeline absent a so-called social licence for the project. If his government applied to the quest of a pro-pipeline consensus in British Columbia the same loose criteria it is using to declare that there is no consensus in sight on electoral reform, the TransMountain pipeline would be dead on arrival. n nLoading... n nLoading...Loading...Loading...Loading...Loading... n&#34; . print(&#39;Title is None&#39;) if df[&#39;data&#39;][0][&#39;passage&#39;][&#39;title&#39;] == None else df[&#39;data&#39;][0][&#39;passage&#39;][&#39;title&#39;] . Title is None . df[&#39;data&#39;][0][&#39;questions&#39;] . [{&#39;answer&#39;: &#39;&#39;, &#39;question&#39;: &#39;What does the text say about National Affairs Columnist, Chantal Hébert?&#39;}, {&#39;answer&#39;: &#34;The prime minister&#39;s capacity to forge a consensus in Parliament, on the federal-provincial front and his own caucus will be tested as some key campaign commitments face their deadlines. There are three potentially troublesome fronts for Trudeau&#39;s Liberal government. He must come up with a coherent response to the voting system. &#34;, &#39;question&#39;: &#39;What does the text say about Canadian Prime Minister Justin Trudeau?&#39;}, {&#39;answer&#39;: &#34;On or before December 1, the special committee exploring reform of Canada&#39;s voting system will report its findings to the government. Democratic reform minister Maryam Monsef made her own consultations and found that there was no consensus within the public as to a preferred voting system. On December 9, Trudeau is tentatively scheduled to meet with the premiers to put the finishing touches on the country&#39;s climate change strategy. &#34;, &#39;question&#39;: &#39;Summarize everything that happened between December 1 to December 9.&#39;}, {&#39;answer&#39;: &#34;December 19 is the deadline for the federal cabinet to decide the fate of Kinder Morgan&#39;s plan to increase the capacity of the TransMountain pipeline. The pipeline links Alberta to the coast of Vancouver. However, Trudeau has long said that he would not proceed with a pipeline absent a social license for the project.&#34;, &#39;question&#39;: &#39;What does the text say about December 19th?&#39;}] . Id, split and time . We expect each id to be unique | Since we&#39;re looking at just the training set we expect split to only have 1 unique value: &#39;train&#39; | I don&#39;t know yet how to interpret the time column, but I think it&#39;s not all too important: Could be how long did labeling this piece took | Or date and time at which labeler started labeling | . | . df[&#39;id&#39;].nunique() == len(df) . True . df[&#39;split&#39;].unique() . array([&#39;train&#39;], dtype=object) . df[&#39;time&#39;].nunique() . 11232 . df[&#39;time&#39;][0] . 1654294771.222219 . EPOCH = datetime(1900, 1, 1) # midnight 1st January 1900 def from_ordinal(ordinal, _epoch=EPOCH): return _epoch + timedelta(days=ordinal) # from_ordinal(df[&#39;time&#39;][0]) . is_topic_based_summarization . This column tells us whether the summarization is topic based or not | What are the other options though? | . topic_based_df = df[&#39;is_topic_based_summarization&#39;].value_counts() topic_based_df.plot(kind=&#39;bar&#39;) plt.title(&#39;Count of (non) topic based summarizations&#39;) plt.ylabel(&#39;Frequency&#39;) plt.xlabel(&#39;Is topic based summarization&#39;); . print(f&#39;Topic based: {round(topic_based_df[False] / len(df) * 100, 2)} % of the data&#39;) print(f&#39;Not topic based: {round(topic_based_df[True] / len(df) * 100, 2)} % of the data&#39;) . Topic based: 80.23 % of the data Not topic based: 19.77 % of the data . labeler . How many unique labelers were there? | How many items did each labeler label | What was the mean amount each labeler labeled | . num_labelers = len(df[&#39;labeler&#39;].unique()) num_labelers . 35 . rename_labelers = [f&#39;labeler {i}&#39; for i in range(1, num_labelers +1)] len(rename_labelers) . 35 . df = df.replace({&#39;labeler&#39;: dict(zip(df[&#39;labeler&#39;].unique(), rename_labelers))}) df.head(2) . id split time labeler is_topic_based_summarization data . 0 Hvwa1M6h1l81jmLcI2WdliTDayc6ik | train | 1.654295e+09 | labeler 1 | True | {&#39;passage&#39;: {&#39;text&#39;: &#39;[Between now and the end... | . 1 tCYeeDnFlAqrHk9HHYV5BnC4JD5eYQ | train | 1.654295e+09 | labeler 2 | False | {&#39;passage&#39;: {&#39;text&#39;: &#39; The hikers had left a m... | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; labeler_count_df = df.groupby(&#39;labeler&#39;).count()[&#39;data&#39;] labeler_count_df.sort_values().plot(kind=&#39;barh&#39;, figsize=(5,10)) mean_val = labeler_count_df.mean() plt.axvline(x=mean_val, color=&#39;r&#39;, linestyle=&#39;--&#39;, label=&#39;mean&#39;) plt.title(&#39;Labelers by contribution&#39;) plt.xlabel(&#39;Number of labeled data&#39;) plt.text(mean_val+50, 17,&#39;mean&#39;, c=&#39;red&#39;, rotation=45); . Let&#39;s finally look at our data . data.passage . How long are the texts on average? | How long are the titles on average? | . data = df[&#39;data&#39;] text_len = 0 title_len = 0 for datapoint in data: text_len += len(datapoint[&#39;passage&#39;][&#39;text&#39;]) title_len += len(datapoint[&#39;passage&#39;][&#39;title&#39;]) if datapoint[&#39;passage&#39;][&#39;title&#39;] != None else 0 print(f&#39;Mean text length: {int(text_len / len(data))} words&#39;) print(f&#39;Mean title length: {int(title_len / len(data))} words&#39;) . Mean text length: 4563 words Mean title length: 19 words . print(data[1][&#39;passage&#39;][&#39;text&#39;][:100]) . The hikers had left a map of the area which gave us a vast layout of the land. It wasn&#39;t good. Ther . data[1][&#39;passage&#39;][&#39;title&#39;] . &#39;The Walking Dead: Winter Chronicles nChapter Four: Five Sisters&#39; . data.questions . How do the answers and qustions look like? | How many question answer pairs are there per datapoint? | . df[&#39;data&#39;][0][&#39;questions&#39;] . [{&#39;answer&#39;: &#39;&#39;, &#39;question&#39;: &#39;What does the text say about National Affairs Columnist, Chantal Hébert?&#39;}, {&#39;answer&#39;: &#34;The prime minister&#39;s capacity to forge a consensus in Parliament, on the federal-provincial front and his own caucus will be tested as some key campaign commitments face their deadlines. There are three potentially troublesome fronts for Trudeau&#39;s Liberal government. He must come up with a coherent response to the voting system. &#34;, &#39;question&#39;: &#39;What does the text say about Canadian Prime Minister Justin Trudeau?&#39;}, {&#39;answer&#39;: &#34;On or before December 1, the special committee exploring reform of Canada&#39;s voting system will report its findings to the government. Democratic reform minister Maryam Monsef made her own consultations and found that there was no consensus within the public as to a preferred voting system. On December 9, Trudeau is tentatively scheduled to meet with the premiers to put the finishing touches on the country&#39;s climate change strategy. &#34;, &#39;question&#39;: &#39;Summarize everything that happened between December 1 to December 9.&#39;}, {&#39;answer&#39;: &#34;December 19 is the deadline for the federal cabinet to decide the fate of Kinder Morgan&#39;s plan to increase the capacity of the TransMountain pipeline. The pipeline links Alberta to the coast of Vancouver. However, Trudeau has long said that he would not proceed with a pipeline absent a social license for the project.&#34;, &#39;question&#39;: &#39;What does the text say about December 19th?&#39;}] . Look at the first question-answer pair . The question being asked does not have an answer in the accompanying text, thus the answer column is empty | . len_question_answer_pairs = df[&#39;data&#39;].apply(lambda x: len(x[&#39;questions&#39;])) len_question_answer_pairs . 0 4 1 5 2 5 3 5 4 6 .. 11227 5 11228 4 11229 4 11230 5 11231 6 Name: data, Length: 11232, dtype: int64 . len_question_answer_pairs.value_counts().sort_values().loc[[i for i in range(1,10)]].plot(kind=&#39;bar&#39;) plt.title(&#39;Question-Answer pairs by frequency&#39;) plt.xlabel(&#39;Number of Question-Answer Pairs&#39;) plt.ylabel(&#39;Frequency&#39;); . 2. Critique Dataset . critiques_url = &quot;https://openaipublic.blob.core.windows.net/critiques/dataset/critiques/&quot; critiques_dataset = load_dataset(&#39;json&#39;, data_files={&#39;train&#39;: critiques_url + &#39;train.jsonl.gz&#39;, &#39;test&#39;: critiques_url + &#39;test.jsonl.gz&#39;}) critiques_dataset . Using custom data configuration default-62122e0587bb4ca2 . Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-62122e0587bb4ca2/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5... . /usr/local/lib/python3.7/dist-packages/datasets/table.py:1806: UserWarning: None values are converted to empty lists when converting array to [{&#39;text&#39;: Value(dtype=&#39;string&#39;, id=None), &#39;category&#39;: Value(dtype=&#39;string&#39;, id=None), &#39;severity&#39;: Value(dtype=&#39;int64&#39;, id=None), &#39;refinement&#39;: Value(dtype=&#39;string&#39;, id=None), &#39;text_quotes&#39;: [{&#39;end&#39;: Value(dtype=&#39;int64&#39;, id=None), &#39;begin&#39;: Value(dtype=&#39;int64&#39;, id=None)}], &#39;category_text&#39;: Value(dtype=&#39;string&#39;, id=None), &#39;response_quotes&#39;: [{&#39;end&#39;: Value(dtype=&#39;int64&#39;, id=None), &#39;begin&#39;: Value(dtype=&#39;int64&#39;, id=None)}]}]. More info: https://github.com/huggingface/datasets/issues/3676. This will raise an error in a future major version of `datasets` f&#34;None values are converted to empty lists when converting array to {feature}. More info: https://github.com/huggingface/datasets/issues/3676. This will raise an error in a future major version of `datasets`&#34; . Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-62122e0587bb4ca2/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5. Subsequent calls will reuse this data. . DatasetDict({ train: Dataset({ features: [&#39;id&#39;, &#39;source_id&#39;, &#39;split&#39;, &#39;time&#39;, &#39;labeler&#39;, &#39;is_topic_based_summarization&#39;, &#39;data&#39;], num_rows: 3001 }) test: Dataset({ features: [&#39;id&#39;, &#39;source_id&#39;, &#39;split&#39;, &#39;time&#39;, &#39;labeler&#39;, &#39;is_topic_based_summarization&#39;, &#39;data&#39;], num_rows: 684 }) }) . Helpfulness Dataset . # helpfulness_dataset = load_dataset(&#39;json&#39;, # data_files={&#39;train&#39;: helpfulness_url + &#39;train.jsonl.gz&#39;, # &#39;test&#39;: helpfulness_url + &#39;test.jsonl.gz&#39;}) # helpfulness_dataset . Assistance Results Dataset . assistance_url = &quot;https://openaipublic.blob.core.windows.net/critiques/assistance&quot; assistance_results_dataset = load_dataset(&#39;json&#39;, data_files={&#39;train&#39;: assistance_url + &#39;.jsonl.gz&#39;}) assistance_results_dataset . Using custom data configuration default-6d94f89731eef64b . Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-6d94f89731eef64b/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5... Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-6d94f89731eef64b/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5. Subsequent calls will reuse this data. . DatasetDict({ train: Dataset({ features: [&#39;source_id&#39;, &#39;source_labeler&#39;, &#39;source_data&#39;, &#39;labels&#39;], num_rows: 404 }) }) .",
            "url": "https://kaykozaronek.github.io/blog/gpt-3/language%20models/ai%20safety/ai%20alignment/dataset/openai/2022/06/29/Exploring-OpenAI's-Critique-Dataset.ipynb.html",
            "relUrl": "/gpt-3/language%20models/ai%20safety/ai%20alignment/dataset/openai/2022/06/29/Exploring-OpenAI's-Critique-Dataset.ipynb.html",
            "date": " • Jun 29, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://kaykozaronek.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://kaykozaronek.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website chronicles my exploration of learning in machines and humans. .",
          "url": "https://kaykozaronek.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://kaykozaronek.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}